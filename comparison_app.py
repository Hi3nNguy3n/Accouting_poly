# Copyright by hiennm22, LocTH5 - BM UDPM
import streamlit as st
import pandas as pd
import os
import glob
import zipfile
import io
import re

# C·ªë g·∫Øng import pypdf v√† h∆∞·ªõng d·∫´n c√†i ƒë·∫∑t n·∫øu thi·∫øu
try:
    import pypdf
except ImportError:
    st.error("Th∆∞ vi·ªán pypdf ch∆∞a ƒë∆∞·ª£c c√†i ƒë·∫∑t. Vui l√≤ng ch·∫°y l·ªánh sau trong terminal: pip install pypdf")
    st.stop()

# --- H√ÄM H·ªñ TR·ª¢ ---
def load_unit_mapping():
    """ƒê·ªçc file Excel mapping v√† tr·∫£ v·ªÅ m·ªôt dictionary t·ª´ Employee Name sang ƒê∆°n v·ªã."""
    try:
        df_mapping = pd.read_excel("FileMau/Tong hop _ Report.xlsx")
        # C·ªôt B l√† Employee Name, C·ªôt E l√† ƒê∆°n v·ªã (theo y√™u c·∫ßu c·ªßa ng∆∞·ªùi d√πng)
        name_col = df_mapping.columns[1]
        unit_col_map = df_mapping.columns[4]
        df_mapping = df_mapping.dropna(subset=[name_col])
        # T·∫°o map, x·ª≠ l√Ω tr∆∞·ªùng h·ª£p t√™n nh√¢n vi√™n tr√πng l·∫∑p (l·∫•y ƒë∆°n v·ªã ƒë·∫ßu ti√™n)
        return df_mapping.set_index(name_col)[unit_col_map].to_dict()
    except FileNotFoundError:
        st.error("L·ªói: Kh√¥ng t√¨m th·∫•y file mapping 'FileMau/Tong hop _ Report.xlsx'. Vui l√≤ng ƒë·∫£m b·∫£o file t·ªìn t·∫°i.")
        st.stop()
    except IndexError:
        st.error("L·ªói: File mapping 'Tong hop _ Report.xlsx' kh√¥ng c√≥ ƒë·ªß 5 c·ªôt (ƒë·ªÉ l·∫•y c·ªôt B v√† E).")
        st.stop()
    except Exception as e:
        st.error(f"L·ªói khi ƒë·ªçc file mapping: {e}")
        st.stop()

st.set_page_config(page_title="ƒê·ªëi chi·∫øu FPT", layout="wide", page_icon="üìä")

st.title("üìä ƒê·ªëi chi·∫øu d·ªØ li·ªáu Grab & B√°o c√°o PDF")
st.write("T·∫£i l√™n c√°c t·ªáp c·ªßa b·∫°n ƒë·ªÉ b·∫Øt ƒë·∫ßu ƒë·ªëi chi·∫øu v√† x·ª≠ l√Ω.")
st.caption("Copyright by LocTH5, Hiennm22 - BM UDPM")

# --- GIAO DI·ªÜN NH·∫¨P LI·ªÜU ---
with st.container(border=True):
    col1, col2, col3 = st.columns([2, 2, 3])
    file_types = ["csv", "xls", "xlsx"]
    with col1:
        st.subheader("1. File Transport")
        uploaded_transport_file = st.file_uploader("T·∫£i l√™n file Transport", type=file_types, label_visibility="collapsed")
    with col2:
        st.subheader("2. File H√≥a ƒë∆°n")
        uploaded_invoice_file = st.file_uploader("T·∫£i l√™n file H√≥a ƒë∆°n", type=file_types, label_visibility="collapsed")
    with col3:
        st.subheader("3. Folder B√°o c√°o (.zip)")
        uploaded_zip_file = st.file_uploader("T·∫£i l√™n file .zip c·ªßa folder b√°o c√°o", type=["zip"], label_visibility="collapsed")

# --- B·∫ÆT ƒê·∫¶U X·ª¨ L√ù KHI C√ì ƒê·ª¶ FILE ---
if uploaded_transport_file is not None and uploaded_invoice_file is not None:
    try:
        employee_to_unit_map = load_unit_mapping()

        # --- 1. ƒê·ªåC V√Ä L√ÄM S·∫†CH D·ªÆ LI·ªÜU G·ªêC ---
        # ƒê·ªçc file transport (CSV ho·∫∑c Excel)
        if uploaded_transport_file.name.endswith('.csv'):
            df_transport = pd.read_csv(uploaded_transport_file, skiprows=8)
        else:
            df_transport = pd.read_excel(uploaded_transport_file, skiprows=8)

        # ƒê·ªçc file h√≥a ƒë∆°n (CSV ho·∫∑c Excel)
        if uploaded_invoice_file.name.endswith('.csv'):
            df_invoice = pd.read_csv(uploaded_invoice_file)
        elif uploaded_invoice_file.name.endswith('.xls'):
            try: # X·ª≠ l√Ω tr∆∞·ªùng h·ª£p file .xls th·ª±c ch·∫•t l√† HTML
                df_invoice = pd.read_html(uploaded_invoice_file)[0]
            except Exception:
                df_invoice = pd.read_excel(uploaded_invoice_file, engine='xlrd')
        else: # .xlsx
            df_invoice = pd.read_excel(uploaded_invoice_file)

        df_transport.columns = df_transport.columns.str.strip()
        df_invoice.columns = df_invoice.columns.str.strip()

        # L·∫•y t√™n c·ªôt ƒë·ªãa ch·ªâ theo ch·ªâ s·ªë v√† ƒë·ªïi t√™n ƒë·ªÉ tr√°nh xung ƒë·ªôt khi merge
        if len(df_transport.columns) > 9: # Ph·∫£i c√≥ √≠t nh·∫•t 10 c·ªôt
            pickup_col_name = df_transport.columns[7]
            dropoff_col_name = df_transport.columns[9]
            df_transport.rename(columns={
                pickup_col_name: 'GEMINI_PICKUP_ADDRESS',
                dropoff_col_name: 'GEMINI_DROPOFF_ADDRESS'
            }, inplace=True)

        if df_invoice.shape[1] < 13:
            st.error(f"File H√≥a ƒë∆°n kh√¥ng c√≥ ƒë·ªß 13 c·ªôt. Ch·ªâ t√¨m th·∫•y {df_invoice.shape[1]} c·ªôt.")
            st.stop()
        rename_dict = {
            df_invoice.columns[1]: 'pdf_link_key',
            df_invoice.columns[12]: 'summary_ma_nhan_hoa_don'
        }
        if len(df_invoice.columns) > 4:
            rename_dict[df_invoice.columns[4]] = 'GEMINI_NGAY_HD_INVOICE' # C·ªôt 5 l√† Ng√†y Hƒê
            rename_dict[df_invoice.columns[5]] = 'HINH_THUC_TT' # C·ªôt 5 l√† Ng√†y Hƒê
            rename_dict[df_invoice.columns[6]] = 'TIEN_TRC_THUE' # C·ªôt 5 l√† Ng√†y Hƒê
            rename_dict[df_invoice.columns[7]] = 'TIEN_THUE8' # C·ªôt 5 l√† Ng√†y Hƒê
            rename_dict[df_invoice.columns[8]] = 'TONG_TIEN' # C·ªôt 5 l√† Ng√†y Hƒê
            rename_dict[df_invoice.columns[15]] = 'NGAY_BOOKING' # C·ªôt 5 l√† Ng√†y Hƒê
            rename_dict[df_invoice.columns[16]] = 'SO_HOA_DON' # C·ªôt 5 l√† Ng√†y Hƒê
        df_invoice.rename(columns=rename_dict, inplace=True)

        # --- 2. H·ª¢P NH·∫§T D·ªÆ LI·ªÜU CSV V√Ä EXCEL ---
        matching_ids = list(set(df_transport['Booking ID'].dropna()) & set(df_invoice['Booking'].dropna()))
        if not matching_ids:
            st.warning("Kh√¥ng t√¨m th·∫•y Booking ID n√†o tr√πng kh·ªõp gi·ªØa hai file ƒë·∫ßu v√†o.")
            st.stop()

        df_merged = pd.merge(df_transport[df_transport['Booking ID'].isin(matching_ids)], df_invoice[df_invoice['Booking'].isin(matching_ids)], left_on='Booking ID', right_on='Booking', suffixes=('_transport', '_invoice'))

        # √Åp d·ª•ng mapping ƒë·ªÉ th√™m c·ªôt 'ƒê∆°n v·ªã'
        df_merged['ƒê∆°n v·ªã'] = df_merged['Employee Name'].map(employee_to_unit_map)
        df_merged['ƒê∆°n v·ªã'].fillna('Kh√¥ng x√°c ƒë·ªãnh', inplace=True)

        # --- 3. X·ª¨ L√ù FOLDER PDF (N·∫æU C√ì) ---
        count_no_pdf = 0
        if uploaded_zip_file is not None:
            pdf_data = []
            with zipfile.ZipFile(uploaded_zip_file, 'r') as zip_ref:
                pdf_file_names = [name for name in zip_ref.namelist() if name.lower().endswith('.pdf') and not name.startswith('__MACOSX')]
                st.info(f"B·∫Øt ƒë·∫ßu x·ª≠ l√Ω {len(pdf_file_names)} file PDF t·ª´ t·ªáp .zip...")
                progress_bar = st.progress(0, text="ƒêang x·ª≠ l√Ω file PDF...")
                for i, filename in enumerate(pdf_file_names):
                    try:
                        key_from_filename = os.path.basename(filename).split('_')[2]
                        with zip_ref.open(filename) as pdf_file:
                            pdf_content = pdf_file.read()
                            pdf_reader = pypdf.PdfReader(io.BytesIO(pdf_content))
                            text = "".join([page.extract_text() or "" for page in pdf_reader.pages])
                            
                            found_code = "Kh√¥ng t√¨m th·∫•y trong PDF"
                            if "M√£ nh·∫≠n h√≥a ƒë∆°n" in text:
                                parts = text.split("M√£ nh·∫≠n h√≥a ƒë∆°n")
                                if len(parts) > 1:
                                    code = parts[1].split('\n')[0].replace(":", "").strip()
                                    if code:
                                        found_code = code
                            
                            # Tr√≠ch xu·∫•t ng√†y h√≥a ƒë∆°n t·ª´ PDF
                            ngay_hd_str = "Kh√¥ng t√¨m th·∫•y"
                            match = re.search(r'Ng√†y\s*(\d{1,2})\s*th√°ng\s*(\d{1,2})\s*nƒÉm\s*(\d{4})', text, re.IGNORECASE)
                            if match:
                                day, month, year = match.groups()
                                ngay_hd_str = f"{day.zfill(2)}/{month.zfill(2)}/{year}"

                            pdf_data.append({
                                'pdf_link_key_str': key_from_filename, 
                                'M√£ h√≥a ƒë∆°n t·ª´ PDF': found_code, 
                                'Ngay_HD_pdf': ngay_hd_str,
                                'pdf_content': pdf_content, 
                                'pdf_filename': os.path.basename(filename)
                            })
                    except Exception as e:
                        st.warning(f"L·ªói khi ƒë·ªçc file {filename} trong zip: {e}")
                    progress_bar.progress((i + 1) / len(pdf_file_names), text=f"ƒêang x·ª≠ l√Ω: {os.path.basename(filename)}")
            
            if pdf_data:
                df_pdf_data = pd.DataFrame(pdf_data)
                df_merged['pdf_link_key_str'] = df_merged['pdf_link_key'].astype(str)
                df_merged = pd.merge(df_merged, df_pdf_data, on='pdf_link_key_str', how='left')
                count_no_pdf = df_merged['pdf_filename'].isnull().sum()

        # --- 4. TH·ªêNG K√ä V√Ä HI·ªÇN TH·ªä ---
        if count_no_pdf > 0:
            st.warning(f"### üî• Ch√∫ √Ω: C√≥ {count_no_pdf} h√≥a ƒë∆°n kh√¥ng c√≥ file PDF t∆∞∆°ng ·ª©ng.")
        st.header("üìà K·∫øt qu·∫£ ƒë·ªëi chi·∫øu")
        with st.container(border=True):
            st.subheader("B·∫£ng th·ªëng k√™ t·ªïng h·ª£p")
            agg_dict = {'S·ªë chuy·∫øn': ('Booking ID', 'count'), 'T·ªïng ti·ªÅn (VND)': ('Total Fare', 'sum')}
            if 'summary_ma_nhan_hoa_don' in df_merged.columns: agg_dict['M√£ nh·∫≠n h√≥a ƒë∆°n (t√≥m t·∫Øt)'] = ('summary_ma_nhan_hoa_don', 'first')
            if 'M√£ h√≥a ƒë∆°n t·ª´ PDF' in df_merged.columns: agg_dict['M√£ h√≥a ƒë∆°n t·ª´ PDF'] = ('M√£ h√≥a ƒë∆°n t·ª´ PDF', lambda x: ", ".join(x.dropna().unique()))

            employee_stats = df_merged.groupby('Employee Name').agg(**agg_dict).reset_index()
            st.dataframe(employee_stats)

            # --- Ch·ª©c nƒÉng t·∫°o v√† t·∫£i B·∫£ng k√™ Excel ---
            try:
                # --- T√¨m t·∫•t c·∫£ c√°c c·ªôt c·∫ßn thi·∫øt m·ªôt c√°ch linh ho·∫°t ---
                def find_col(df, possibilities):
                    for p in possibilities:
                        if p in df.columns:
                            return p
                    return None

                date_cols = ['Date', 'Date of Trip', 'Trip Date', 'Ng√†y', 'Date & Time (GMT+7)']
                date_col_name = find_col(df_merged, date_cols)
                # Sau khi ƒë·ªïi t√™n, ch√∫ng ta c√≥ th·ªÉ t√¨m tr·ª±c ti·∫øp v√† ch·∫Øc ch·∫Øn h∆°n
                pickup_col_name = 'GEMINI_PICKUP_ADDRESS' if 'GEMINI_PICKUP_ADDRESS' in df_merged.columns else None
                dropoff_col_name = 'GEMINI_DROPOFF_ADDRESS' if 'GEMINI_DROPOFF_ADDRESS' in df_merged.columns else None

                if date_col_name is None:
                    # L·ªñI NGHI√äM TR·ªåNG: C·ªôt ng√†y th√°ng l√† b·∫Øt bu·ªôc. Hi·ªÉn th·ªã l·ªói v√† d·ª´ng l·∫°i.
                    try:
                        uploaded_transport_file.seek(0)
                        if uploaded_transport_file.name.endswith('.csv'):
                            header_list = pd.read_csv(uploaded_transport_file, skiprows=8, nrows=1).columns.tolist()
                        else:
                            header_list = pd.read_excel(uploaded_transport_file, skiprows=8, nrows=1).columns.tolist()
                        st.error(f"**L·ªói B·∫£ng k√™: Kh√¥ng th·ªÉ t√¨m th·∫•y c·ªôt Ng√†y th√°ng.** Vui l√≤ng cho t√¥i bi·∫øt t√™n c·ªôt ng√†y th√°ng ch√≠nh x√°c t·ª´ danh s√°ch b√™n d∆∞·ªõi. **C√°c c·ªôt t√¨m ƒë∆∞·ª£c:** `{header_list}`")
                    except Exception as e:
                        st.error(f"L·ªói B·∫£ng k√™: Kh√¥ng t√¨m th·∫•y c·ªôt ng√†y th√°ng. L·ªói khi ƒë·ªçc c·ªôt: {e}")
                else:
                    # C·ªôt ng√†y th√°ng ƒë√£ ƒë∆∞·ª£c t√¨m th·∫•y, ti·∫øp t·ª•c x·ª≠ l√Ω.
                    # Hi·ªÉn th·ªã c·∫£nh b√°o n·∫øu kh√¥ng t√¨m th·∫•y c√°c c·ªôt kh√¥ng b·∫Øt bu·ªôc.
                    if not pickup_col_name:
                        st.warning("C·∫£nh b√°o: Kh√¥ng t√¨m th·∫•y c·ªôt 'ƒê·ªãa ch·ªâ ƒë√≥n' (Pick-up Address). C·ªôt n√†y s·∫Ω b·ªã b·ªè tr·ªëng trong file Excel.")
                    if not dropoff_col_name:
                        st.warning("C·∫£nh b√°o: Kh√¥ng t√¨m th·∫•y c·ªôt 'ƒê·ªãa ch·ªâ tr·∫£' (Drop-off Address). C·ªôt n√†y s·∫Ω b·ªã b·ªè tr·ªëng trong file Excel.")

                    df_merged['Date_dt'] = pd.to_datetime(df_merged[date_col_name], errors='coerce')
                    start_date = df_merged['Date_dt'].min()
                    end_date = df_merged['Date_dt'].max()

                    @st.cache_data
                    def generate_bang_ke_excel(_df, s_date, e_date, _d_col, _p_col, _do_col):
                        from openpyxl import load_workbook
                        from openpyxl.styles import Font
                        template_path = "FileMau/BangKe.xlsx"
                        wb = load_workbook(template_path)
                        ws = wb.active
                        ws['C4'] = s_date.strftime('%d/%m/%Y') if pd.notna(s_date) else "N/A"
                        ws['C5'] = e_date.strftime('%d/%m/%Y') if pd.notna(e_date) else "N/A"
                        start_row = 8
                        for i, row in _df.reset_index(drop=True).iterrows():
                            ws.cell(row=start_row + i, column=1, value=i + 1)
                            ws.cell(row=start_row + i, column=2, value=row['Booking ID'])
                            ws.cell(row=start_row + i, column=3, value=f" {row['Employee Name']}")
                            if _p_col:
                                ws.cell(row=start_row + i, column=4, value=row[_p_col])
                            if _do_col:
                                ws.cell(row=start_row + i, column=5, value=row[_do_col])
                            # ws.cell(row=start_row + i, column=6, value=row['Date_dt'].strftime('%d/%m/%Y') if pd.notna(row['Date_dt']) else row[_d_col])
                            # ws.cell(row=start_row + i, column=7, value=row['Total Fare'])
                            if 'GEMINI_NGAY_HD_INVOICE' in row and pd.notna(row['GEMINI_NGAY_HD_INVOICE']):
                                ws.cell(row=start_row + i, column=6, value=row['GEMINI_NGAY_HD_INVOICE'])
                            ws.cell(row=start_row + i, column=7, value=row['HINH_THUC_TT'])
                            ws.cell(row=start_row + i, column=8, value="{:,.0f}".format(row['TIEN_TRC_THUE']))
                            ws.cell(row=start_row + i, column=9, value="{:,.0f}".format(row['TIEN_THUE8']))
                            ws.cell(row=start_row + i, column=10, value="{:,.0f}".format(row['TONG_TIEN']))
                            ws.cell(row=start_row + i, column=11, value=row['NGAY_BOOKING'])
                            ws.cell(row=start_row + i, column=12, value=row['pdf_link_key'])
                        
                        total_row_index = start_row + len(_df)
                        total_label_cell = ws.cell(row=total_row_index, column=7, value="T·ªïng c·ªông")
                        total_label_cell.font = Font(bold=True)

                        total_tien_trc_thue = _df['TIEN_TRC_THUE'].sum()
                        total_tien_thue8 = _df['TIEN_THUE8'].sum()
                        total_tong_tien = _df['TONG_TIEN'].sum()

                        total_value_cell_8 = ws.cell(row=total_row_index, column=8, value="{:,.0f}".format(total_tien_trc_thue))
                        total_value_cell_8.font = Font(bold=True)
                        total_value_cell_9 = ws.cell(row=total_row_index, column=9, value="{:,.0f}".format(total_tien_thue8))
                        total_value_cell_9.font = Font(bold=True)
                        total_value_cell_10 = ws.cell(row=total_row_index, column=10, value="{:,.0f}".format(total_tong_tien))
                        total_value_cell_10.font = Font(bold=True)
                        
                        excel_buffer = io.BytesIO()
                        wb.save(excel_buffer)
                        return excel_buffer.getvalue()

                    st.divider()
                    st.subheader("T·∫£i B·∫£ng K√™")

                    # --- T√πy ch·ªçn 1: T·∫£i file ZIP theo ƒê∆°n v·ªã ---
                    st.markdown("##### üì• T·∫£i B·∫£ng k√™ theo ƒê∆°n v·ªã (.zip)")
                    
                    unit_col = 'ƒê∆°n v·ªã'
                    if unit_col not in df_merged.columns:
                        st.error(f"L·ªói: Kh√¥ng t√¨m th·∫•y c·ªôt '{unit_col}'. Qu√° tr√¨nh mapping c√≥ th·ªÉ ƒë√£ th·∫•t b·∫°i.")
                    else:
                        # --- Part 1: Download for a single unit with PDFs ---
                        st.markdown("###### T·∫£i cho 1 ƒë∆°n v·ªã (k√®m h√≥a ƒë∆°n PDF)")
                        if 'pdf_content' not in df_merged.columns:
                            st.warning("Ch∆∞a c√≥ d·ªØ li·ªáu PDF. Vui l√≤ng t·∫£i l√™n file .zip ch·ª©a c√°c h√≥a ƒë∆°n ƒë·ªÉ s·ª≠ d·ª•ng ch·ª©c nƒÉng n√†y.")
                        else:
                            unique_units_for_select = sorted(df_merged[unit_col].dropna().unique())
                            selected_unit = st.selectbox("Ch·ªçn ƒë∆°n v·ªã", unique_units_for_select)

                            if selected_unit:
                                df_unit = df_merged[df_merged[unit_col] == selected_unit]
                                
                                @st.cache_data
                                def create_zip_for_unit_with_pdfs(_unit_df, _unit_name):
                                    zip_buffer = io.BytesIO()
                                    with zipfile.ZipFile(zip_buffer, 'w', zipfile.ZIP_DEFLATED) as zip_file:
                                        start_date_unit = _unit_df['Date_dt'].min()
                                        end_date_unit = _unit_df['Date_dt'].max()
                                        excel_data = generate_bang_ke_excel(_unit_df, start_date_unit, end_date_unit, date_col_name, pickup_col_name, dropoff_col_name)
                                        safe_unit_name = "".join(c for c in str(_unit_name) if c.isalnum() or c in (' ', '_')).rstrip()
                                        excel_filename = f"BangKe_{safe_unit_name}_{start_date_unit.strftime('%Y%m%d') if pd.notna(start_date_unit) else 'nodate'}_{end_date_unit.strftime('%Y%m%d') if pd.notna(end_date_unit) else 'nodate'}.xlsx"
                                        zip_file.writestr(excel_filename, excel_data)

                                        df_pdfs = _unit_df[_unit_df['pdf_content'].notna()]
                                        for _, row in df_pdfs.iterrows():
                                            zip_file.writestr(f"HOA_DON_PDF/{row['pdf_filename']}", row['pdf_content'])
                                    return zip_buffer.getvalue()

                                zip_data_single = create_zip_for_unit_with_pdfs(df_unit, selected_unit)
                                
                                safe_unit_name_zip = "".join(c for c in str(selected_unit) if c.isalnum() or c in (' ', '_')).rstrip()
                                zip_filename_single = f"BangKe_va_HoaDon_{safe_unit_name_zip}.zip"
                                
                                st.download_button(
                                    label=f"üì• T·∫£i ZIP cho '{selected_unit}'",
                                    data=zip_data_single,
                                    file_name=zip_filename_single,
                                    mime="application/zip",
                                    use_container_width=True
                                )

                        st.divider()

                        # --- Part 2: Download for all units (Excel only) ---
                        st.markdown("###### T·∫£i cho t·∫•t c·∫£ ƒë∆°n v·ªã (ch·ªâ B·∫£ng k√™ Excel)")
                        st.info(f"D·ªØ li·ªáu s·∫Ω ƒë∆∞·ª£c gom nh√≥m theo c·ªôt 'ƒê∆°n v·ªã' ƒë∆∞·ª£c map t·ª´ file 'Tong hop _ Report.xlsx'.")

                        if st.button("üì¶ T·∫°o v√† T·∫£i file .zip cho t·∫•t c·∫£ ƒë∆°n v·ªã"):
                            zip_buffer = io.BytesIO()
                            with zipfile.ZipFile(zip_buffer, 'w', zipfile.ZIP_DEFLATED) as zip_file:
                                unique_units = df_merged[unit_col].dropna().unique()
                                st.info(f"B·∫Øt ƒë·∫ßu t·∫°o {len(unique_units)} file B·∫£ng k√™ cho c√°c ƒë∆°n v·ªã...")
                                progress_bar_zip = st.progress(0)
                                for i, unit in enumerate(unique_units):
                                    df_unit = df_merged[df_merged[unit_col] == unit]
                                    start_date_unit = df_unit['Date_dt'].min()
                                    end_date_unit = df_unit['Date_dt'].max()
                                    excel_data_unit = generate_bang_ke_excel(df_unit, start_date_unit, end_date_unit, date_col_name, pickup_col_name, dropoff_col_name)
                                    safe_unit_name = "".join(c for c in str(unit) if c.isalnum() or c in (' ', '_')).rstrip()
                                    file_name = f"BangKe_{safe_unit_name}_{start_date_unit.strftime('%Y%m%d') if pd.notna(start_date_unit) else 'nodate'}_{end_date_unit.strftime('%Y%m%d') if pd.notna(end_date_unit) else 'nodate'}.xlsx"
                                    zip_file.writestr(file_name, excel_data_unit)
                                    progress_bar_zip.progress((i + 1) / len(unique_units))

                                zip_data = zip_buffer.getvalue()
                                
                                st.download_button(
                                    label=f"‚úÖ T·∫£i v·ªÅ ZIP ({len(unique_units)} files)",
                                    data=zip_data,
                                    file_name="BangKe_Theo_Don_Vi.zip",
                                    mime="application/zip",
                                    use_container_width=True,
                                    key='download_all_units'
                                )

                    st.divider()
                    # --- T√πy ch·ªçn 2: T·∫£i file t·ªïng h·ª£p ---
                    st.markdown("##### üì• T·∫£i B·∫£ng k√™ T·ªïng h·ª£p (1 file)")
                    excel_data = generate_bang_ke_excel(df_merged, start_date, end_date, date_col_name, pickup_col_name, dropoff_col_name)
                    st.download_button(
                        label="üì• T·∫£i v·ªÅ B·∫£ng k√™ T·ªïng h·ª£p",
                        data=excel_data,
                        file_name=f"BangKe_TongHop_{start_date.strftime('%Y%m%d') if pd.notna(start_date) else ''}_{end_date.strftime('%Y%m%d') if pd.notna(end_date) else ''}.xlsx",
                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                        use_container_width=True
                    )

            except FileNotFoundError:
                st.error("L·ªói: Kh√¥ng t√¨m th·∫•y file m·∫´u 'FileMau/BangKe.xlsx'. Vui l√≤ng ƒë·∫£m b·∫£o file t·ªìn t·∫°i.")
            except Exception as e:
                st.error(f"ƒê√£ x·∫£y ra l·ªói khi t·∫°o file B·∫£ng k√™: {e}")


        # --- B·∫£ng H√≥a ƒë∆°n kh√¥ng c√≥ PDF ---
        if uploaded_zip_file is not None and 'pdf_filename' in df_merged.columns:
            with st.container(border=True):
                st.subheader("üö´ H√≥a ƒë∆°n kh√¥ng c√≥ file PDF")
                invoices_no_pdf = df_merged[df_merged['pdf_filename'].isnull()].copy()
                if not invoices_no_pdf.empty:
                    st.warning(f"T√¨m th·∫•y {len(invoices_no_pdf)} h√≥a ƒë∆°n kh√¥ng c√≥ file PDF t∆∞∆°ng ·ª©ng trong t·ªáp zip.")
                    # Ch·ªçn c√°c c·ªôt c·∫ßn hi·ªÉn th·ªã ƒë·ªÉ ng∆∞·ªùi d√πng d·ªÖ d√†ng x√°c ƒë·ªãnh h√≥a ƒë∆°n b·ªã thi·∫øu
                    display_cols = ['Employee Name', 'Booking ID', 'Date', 'Trip Type', 'Total Fare', 'pdf_link_key']
                    # L·ªçc ra nh·ªØng c·ªôt th·ª±c s·ª± t·ªìn t·∫°i trong dataframe ƒë·ªÉ tr√°nh l·ªói
                    existing_cols = [col for col in display_cols if col in invoices_no_pdf.columns]
                    st.dataframe(invoices_no_pdf[existing_cols])
                else:
                    st.success("T·∫•t c·∫£ h√≥a ƒë∆°n trong danh s√°ch ƒë·ªëi chi·∫øu ƒë·ªÅu c√≥ file PDF t∆∞∆°ng ·ª©ng.")

        # --- 5. KHU V·ª∞C T·∫¢I V·ªÄ ---
        if 'pdf_content' in df_merged.columns:
            with st.container(border=True):
                st.subheader("üì• T·∫£i v·ªÅ b√°o c√°o PDF theo nh√¢n vi√™n")
                employee_list = sorted(df_merged['Employee Name'].unique())
                selected_employee = st.selectbox("Ch·ªçn nh√¢n vi√™n ƒë·ªÉ t·∫£i v·ªÅ", employee_list)

                if selected_employee:
                    employee_df = df_merged[(df_merged['Employee Name'] == selected_employee) & (df_merged['pdf_content'].notna())]
                    if employee_df.empty:
                        st.warning(f"Kh√¥ng t√¨m th·∫•y file PDF n√†o cho nh√¢n vi√™n {selected_employee}.")
                    else:
                        zip_buffer = io.BytesIO()
                        with zipfile.ZipFile(zip_buffer, 'w', zipfile.ZIP_DEFLATED) as zip_file:
                            for index, row in employee_df.iterrows():
                                zip_file.writestr(row['pdf_filename'], row['pdf_content'])
                        
                        st.download_button(
                            label=f"T·∫£i xu·ªëng {len(employee_df)} file PDF cho {selected_employee}",
                            data=zip_buffer.getvalue(),
                            file_name=f"{selected_employee}_reports.zip",
                            mime="application/zip",
                            use_container_width=True
                        )

        # --- 6. CHI TI·∫æT CHUY·∫æN ƒêI ---
        with st.container(border=True):
            st.subheader("üìÑ Chi ti·∫øt c√°c chuy·∫øn ƒëi (cho nh√¢n vi√™n c√≥ >1 chuy·∫øn)")
            multi_trip_employees = employee_stats[employee_stats['S·ªë chuy·∫øn'] > 1]
            if multi_trip_employees.empty:
                st.info("Kh√¥ng c√≥ nh√¢n vi√™n n√†o c√≥ nhi·ªÅu h∆°n m·ªôt chuy·∫øn ƒëi.")
            else:
                for index, row in multi_trip_employees.iterrows():
                    with st.expander(f"Xem chi ti·∫øt cho: {row['Employee Name']} ({row['S·ªë chuy·∫øn']} chuy·∫øn)"):
                        st.dataframe(df_merged[df_merged['Employee Name'] == row['Employee Name']])

    except Exception as e:
        st.error(f"ƒê√£ x·∫£y ra l·ªói trong qu√° tr√¨nh x·ª≠ l√Ω: {e}")
        st.exception(e) # In ra chi ti·∫øt l·ªói ƒë·ªÉ debug
